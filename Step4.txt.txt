4) [ Bonus ] Explain how your program could handle high data volumes, exceeding RAM size on a single machine. For this step an explanation is enough.

In the case of using large amounts of data, it will be necessary to use generator expressions, which will allow not to load the RAM with all the data at once, but to process one element at a time. This will be similar to using RDD in Spark with the "lazy evaluation" principle.